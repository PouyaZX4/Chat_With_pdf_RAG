Great! I’ll create a professional and compelling README for your GitHub project—a PDF chatbot powered by LLM using RAG (Retrieval-Augmented Generation). It will target researchers and AI engineers, outline the purpose and usage, and include a list of required libraries.

I’ll let you know once it’s ready.


# PDF-RAG Chatbot

This project implements a **Retrieval-Augmented Generation (RAG)** system for conversational question-answering over PDF documents. Users upload one or more PDF files via a Streamlit interface, and the app extracts and indexes their contents. The system uses semantic embeddings (from a SentenceTransformer model) stored in a Chroma vector database to retrieve relevant passages, and a transformer-based language model (Qwen2-1.5B) to generate answers. In the RAG paradigm, a *retriever* finds relevant content and a *generator* produces the answer. This demo is aimed at researchers and developers, and is **not** intended for production use.

## Features

* **PDF Upload:** Users can upload multiple PDF documents using Streamlit’s `st.file_uploader` widget. Each PDF’s text is automatically extracted and prepared for indexing.
* **Embedding & Indexing:** The text from PDFs is split into passages and converted into dense embeddings using the `all-MiniLM-L6-v2` Sentence-Transformers model (384-dimensional vectors). These embeddings are stored in a Chroma DB collection, an open-source vector database optimized for dense embeddings and similarity search.
* **Retrieval-Augmented Generation:** When a user asks a question, the query is encoded into an embedding and the system retrieves the most semantically relevant passages from the vector store. This follows the RAG approach: the retrieved context is then fed to the language model (retriever + generator).
* **Answer Generation:** Answers are generated by the Qwen2-1.5B model (a 1.5-billion-parameter LLM by Alibaba Cloud) via Hugging Face’s text-generation pipeline. Qwen2 has demonstrated strong performance on language tasks, and the pipeline API provides a simple interface for inference.
* **Interactive Chat UI:** The interface is built with Streamlit and provides a chat-like experience. User and bot messages are formatted with custom HTML/CSS templates to clearly distinguish the conversation turns.
* **GPU Acceleration:** If a CUDA-capable GPU is available, the system will use it (through PyTorch) to speed up embedding computation and text generation.
* **Prototype Caution:** *Note:* This project is a research/demo prototype and is not production-ready. It is intended for experimentation and exploration, not deployment.

## Installation
1. Clone the repository:
```
git clone https://github.com/PouyaZX4/PDF_Chatbot_with_HF_LLM.git
cd your-repo-name
```

2. Create a virtual environment (recommended):

```
python -m venv venv
python -m venv venv
source venv/bin/activate
3. Install the required dependencies:

pip install -r requirements.txt
```
3. Install the required dependencies:
(You'll need to create a requirements.txt file. See the next section.)
```
requirements.txt
Create a file named requirements.txt in the root of your project and add the following content:

streamlit
PyPDF2
transformers
langchain
langchain-huggingface
langchain-community
sentence-transformers
torch
```
4. Running the Application
Ensure your virtual environment is active.
```
Run the Streamlit application:

streamlit run main.py
```
Open your web browser and navigate to the URL displayed in your terminal (usually http://localhost:8501).
## How It Works

1. **Upload and Preprocessing:** The user uploads PDFs via the web app. The app reads each PDF (e.g. using PyMuPDF) and splits the text into manageable chunks (e.g. paragraphs or fixed-length segments).
2. **Embedding & Indexing:** Each text chunk is passed through the `all-MiniLM-L6-v2` model to produce a semantic embedding. These embeddings (with metadata like document/page IDs) are inserted into a Chroma DB collection. Chroma is an open-source vector database optimized for dense embeddings and similarity search.
3. **Question & Retrieval:** When the user asks a question, the query is similarly embedded. The system performs a nearest-neighbors search in the Chroma index to find the most relevant passages. This retrieval step is the RAG *retriever* component.
4. **Answer Generation:** The retrieved passages are combined with the user’s question to form a prompt. This prompt is fed to the Qwen2-1.5B model using Hugging Face’s pipeline API. The model (running locally) generates a response that leverages both the question and the context.
5. **Response Display:** The generated answer is returned to the Streamlit app and displayed as a bot message. The interface uses HTML-styled message bubbles so that user queries and AI responses appear as a chat conversation.

## Requirements

* **Python:** Version 3.8 or higher.
* **Streamlit:** For the web app interface (uploading files and rendering the chat UI).
* **PyTorch & CUDA:** The Torch library (with CUDA support if a GPU is available) for running the models.
* **Transformers:** Hugging Face Transformers library for loading the Qwen2-1.5B model and pipeline.
* **Sentence-Transformers:** Provides the `all-MiniLM-L6-v2` model for computing embeddings.
* **ChromaDB:** The vector store for indexing and querying embeddings.
* **PDF Parsing:** A library such as PyMuPDF (or PyPDF2) to extract text from PDF files.
* **Other:** Any additional dependencies for HTML templating or auxiliary functionality in Streamlit (e.g. Jinja2 if used).

## Acknowledgments

* **Retrieval-Augmented Generation (RAG):** The system is inspired by the RAG approach in open-domain QA, which combines retrieval and generation.
* **Qwen2 LLM:** We use the Qwen2-1.5B model by Alibaba Cloud (as released on Hugging Face).
* **Hugging Face Transformers:** For the model implementations and the easy-to-use pipeline API.
* **Sentence-Transformers:** The `all-MiniLM-L6-v2` embedding model is provided by the Sentence Transformers library.
* **ChromaDB:** The vector database for fast embedding search.
* **Streamlit:** The framework for building the interactive user interface.
